{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e407a1b",
   "metadata": {},
   "source": [
    "# ClutchAI Sandbox\n",
    "\n",
    "__GOAL__ \n",
    "\n",
    "Create an Agentic AI assistant for Yahoo Fantasy Basketball League.\n",
    "\n",
    "__ReACT ClutchAI Agent Components__\n",
    "\n",
    "Live Data - LangChain Tools:\n",
    "1. Add YahooFantasy API as a Tool\n",
    "2. Add Josh Llyod Youtube Transcripts to VectorDB\n",
    "3. Add Tool to webscrape basketball monster data and hashtag data\n",
    "4. Add nba_api as a Tool\n",
    "\n",
    "Static Data - VectorDB:\n",
    "\n",
    "5. Add Youtube Tool to get transcript from any video\n",
    "6. Add sample weekly summary to VectorDB as example\n",
    "7. Add articles online\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Test Cases__\n",
    "- Give me a weekly summary from last week\n",
    "- Who is more likely to win in week A vs week B\n",
    "- Who is hot on the waiver wire?\n",
    "- Is player A for player B a good trade?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca91b33c",
   "metadata": {},
   "source": [
    "#### 0. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34bca149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env from: /Users/matt/Code/ClutchAI/.env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Load .env file from the project root (parent directory of notebook/)\n",
    "# Resolve the path to get the absolute path to the .env file\n",
    "env_file_location = Path('..').resolve()\n",
    "load_dotenv(dotenv_path=env_file_location / \".env\")\n",
    "print(f\"Loading .env from: {env_file_location / '.env'}\\n\")\n",
    "\n",
    "# Set env variables\n",
    "YAHOO_CONSUMER_KEY = os.environ.get('YAHOO_CLIENT_ID', \"<INSERT_>\")\n",
    "YAHOO_CONSUMER_SECRET = os.environ.get('YAHOO_CLIENT_SECRET', \"<INSERT>\")\n",
    "YAHOO_LEAGUE_ID = 58930\n",
    "GAME_CODE = \"nba\"\n",
    "GAME_ID=466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1687477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded:\n",
      "  ✓ YAHOO_CLIENT_ID: dj0yJmk9Ml + ...\n",
      "  ✓ YAHOO_CLIENT_SECRET: 967c74034e + ...\n",
      "  ✓ OPENAI_API_KEY: sk-proj-4A + ...\n",
      "  ✓ LANGSMITH_API_KEY: lsv2_pt_7c + ...\n"
     ]
    }
   ],
   "source": [
    "# Show which env variables were loaded\n",
    "env_vars_to_check = ['YAHOO_CLIENT_ID', 'YAHOO_CLIENT_SECRET', 'OPENAI_API_KEY', 'LANGSMITH_API_KEY']\n",
    "print(\"Environment variables loaded:\")\n",
    "for var in env_vars_to_check:\n",
    "    value = os.environ.get(var)\n",
    "    if value:\n",
    "        print(f\"  ✓ {var}: {value[:10]} + ...\")\n",
    "    else:\n",
    "        print(f\"  ✗ {var}: NOT SET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889aaf1",
   "metadata": {},
   "source": [
    "#### 1. Connect to YahooFantasy League Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb46bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yfpy.query import YahooFantasySportsQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3388365",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = YahooFantasySportsQuery(\n",
    "    league_id=YAHOO_LEAGUE_ID,\n",
    "    game_code=\"nba\",\n",
    "    game_id= GAME_ID,\n",
    "    env_var_fallback = True,\n",
    "    env_file_location = env_file_location,\n",
    "    save_token_data_to_env_file = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3383caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'allow_add_to_dl_extra_pos': 1,\n",
       " 'current_week': 7,\n",
       " 'draft_status': 'postdraft',\n",
       " 'edit_key': '2025-12-05',\n",
       " 'end_date': '2026-04-05',\n",
       " 'end_week': 23,\n",
       " 'felo_tier': 'gold',\n",
       " 'game_code': 'nba',\n",
       " 'iris_group_chat_id': None,\n",
       " 'is_cash_league': 0,\n",
       " 'is_highscore': False,\n",
       " 'is_plus_league': 0,\n",
       " 'is_pro_league': 0,\n",
       " 'league_id': '58930',\n",
       " 'league_key': '466.l.58930',\n",
       " 'league_type': 'private',\n",
       " 'league_update_timestamp': 1764924473,\n",
       " 'logo_url': 'https://yahoofantasysports-res.cloudinary.com/image/upload/t_s192sq/fantasy-logos/56479288575_ec9899.jpg',\n",
       " 'matchup_week': 7,\n",
       " 'name': 'TK Fiji Fantasy 2024/25',\n",
       " 'num_teams': 12,\n",
       " 'renew': '454_14696',\n",
       " 'renewed': None,\n",
       " 'roster_type': 'date',\n",
       " 'scoring_type': 'headone',\n",
       " 'season': 2025,\n",
       " 'start_date': '2025-10-21',\n",
       " 'start_week': 1,\n",
       " 'url': 'https://basketball.fantasysports.yahoo.com/nba/58930',\n",
       " 'weekly_deadline': 'intraday'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data to pull from Yahoo Fantasy\n",
    "league_meta = query.get_league_metadata()\n",
    "league_meta_dict = json.loads(league_meta.to_json())\n",
    "print(len(league_meta))\n",
    "league_meta_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10eec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing get_team_stats_by_week for different weeks:\n",
      "======================================================================\n",
      "\n",
      "Week: current\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "Week: 1\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "Week: 2\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "Week: 3\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "Week: 4\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "Week: 5\n",
      "----------------------------------------------------------------------\n",
      "✗ KeyError: 'team_projected_points'\n",
      "  This means the API response is missing a required field\n",
      "\n",
      "======================================================================\n",
      "Test complete!\n"
     ]
    }
   ],
   "source": [
    "# Test get_team_stats_by_week API directly\n",
    "# Let's see what the actual response looks like for different weeks\n",
    "\n",
    "team_id = 6  # KATmandu Climbers\n",
    "weeks_to_test = [\"current\", 1, 2, 3, 4, 5]\n",
    "\n",
    "print(\"Testing get_team_stats_by_week for different weeks:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for week in weeks_to_test:\n",
    "    print(f\"\\nWeek: {week}\")\n",
    "    print(\"-\" * 70)\n",
    "    try:\n",
    "        data = query.get_team_stats_by_week(team_id, week)\n",
    "        print(f\"✓ Success! Got data for week {week}\")\n",
    "        \n",
    "        # Try to see what fields are available\n",
    "        if hasattr(data, '__dict__'):\n",
    "            print(f\"  Available attributes: {list(data.__dict__.keys())[:10]}...\")  # First 10\n",
    "            # Check if team_projected_points exists\n",
    "            if hasattr(data, 'team_projected_points'):\n",
    "                print(f\"  ✓ team_projected_points exists: {data.team_projected_points}\")\n",
    "            else:\n",
    "                print(f\"  ✗ team_projected_points does NOT exist\")\n",
    "            \n",
    "            # Check if team_points exists\n",
    "            if hasattr(data, 'team_points'):\n",
    "                print(f\"  ✓ team_points exists: {data.team_points}\")\n",
    "            else:\n",
    "                print(f\"  ✗ team_points does NOT exist\")\n",
    "                \n",
    "            # Try to convert to dict to see all fields\n",
    "            try:\n",
    "                data_dict = data.__dict__\n",
    "                print(f\"  All fields: {list(data_dict.keys())}\")\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"  Data is a dict with keys: {list(data.keys())[:10]}...\")\n",
    "            if 'team_projected_points' in data:\n",
    "                print(f\"  ✓ team_projected_points exists: {data['team_projected_points']}\")\n",
    "            else:\n",
    "                print(f\"  ✗ team_projected_points does NOT exist\")\n",
    "        else:\n",
    "            print(f\"  Data type: {type(data)}\")\n",
    "            print(f\"  Data: {str(data)[:200]}...\")\n",
    "            \n",
    "    except KeyError as e:\n",
    "        print(f\"✗ KeyError: {e}\")\n",
    "        print(f\"  This means the API response is missing a required field\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Test complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938d153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with POINTS league (ID: 229522)\n",
      "======================================================================\n",
      "Step 1: Getting all teams in the league...\n",
      "======================================================================\n",
      "✓ Found 10 teams\n",
      "  Team 1: b'Cunning Ham Jerky'\n",
      "  Team 2: b\"Luka's LeGOAT Cheese Puffs\"\n",
      "  Team 3: b'The Banana Splitters'\n",
      "  Team 4: b'Trust the Tiramisu'\n",
      "  Team 5: b'Dwane(Pound) the rock (Cake)sy'\n",
      "  Team 6: b\"Jontay's Jalebi\"\n",
      "  Team 7: b'Day to Daynishes'\n",
      "  Team 8: b'Just vibes'\n",
      "  Team 9: b'THE HALIBAN HALVA'\n",
      "  Team 10: b'Dubai Chocolateers'\n",
      "\n",
      "Found 10 teams to test\n",
      "\n",
      "======================================================================\n",
      "Step 2: Testing get_team_stats_by_week for different teams and weeks\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Testing Team 1 (b'Cunning Ham Jerky')\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 1, Week current\n",
      "✓ SUCCESS! Team 1, Week 1\n",
      "✓ SUCCESS! Team 1, Week 2\n",
      "✓ SUCCESS! Team 1, Week 3\n",
      "✓ SUCCESS! Team 1, Week 4\n",
      "✓ SUCCESS! Team 1, Week 5\n",
      "✓ SUCCESS! Team 1, Week 6\n",
      "✓ SUCCESS! Team 1, Week 7\n",
      "✓ SUCCESS! Team 1, Week 8\n",
      "\n",
      "======================================================================\n",
      "Testing Team 2 (b\"Luka's LeGOAT Cheese Puffs\")\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 2, Week current\n",
      "✓ SUCCESS! Team 2, Week 1\n",
      "✓ SUCCESS! Team 2, Week 2\n",
      "✓ SUCCESS! Team 2, Week 3\n",
      "✓ SUCCESS! Team 2, Week 4\n",
      "✓ SUCCESS! Team 2, Week 5\n",
      "✓ SUCCESS! Team 2, Week 6\n",
      "✓ SUCCESS! Team 2, Week 7\n",
      "✓ SUCCESS! Team 2, Week 8\n",
      "\n",
      "======================================================================\n",
      "Testing Team 3 (b'The Banana Splitters')\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 3, Week current\n",
      "✓ SUCCESS! Team 3, Week 1\n",
      "✓ SUCCESS! Team 3, Week 2\n",
      "✓ SUCCESS! Team 3, Week 3\n",
      "✓ SUCCESS! Team 3, Week 4\n",
      "✓ SUCCESS! Team 3, Week 5\n",
      "✓ SUCCESS! Team 3, Week 6\n",
      "✓ SUCCESS! Team 3, Week 7\n",
      "✓ SUCCESS! Team 3, Week 8\n",
      "\n",
      "======================================================================\n",
      "Testing Team 4 (b'Trust the Tiramisu')\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 4, Week current\n",
      "✓ SUCCESS! Team 4, Week 1\n",
      "✓ SUCCESS! Team 4, Week 2\n",
      "✓ SUCCESS! Team 4, Week 3\n",
      "✓ SUCCESS! Team 4, Week 4\n",
      "✓ SUCCESS! Team 4, Week 5\n",
      "✓ SUCCESS! Team 4, Week 6\n",
      "✓ SUCCESS! Team 4, Week 7\n",
      "✓ SUCCESS! Team 4, Week 8\n",
      "\n",
      "======================================================================\n",
      "Testing Team 5 (b'Dwane(Pound) the rock (Cake)sy')\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 5, Week current\n",
      "✓ SUCCESS! Team 5, Week 1\n",
      "✓ SUCCESS! Team 5, Week 2\n",
      "✓ SUCCESS! Team 5, Week 3\n",
      "✓ SUCCESS! Team 5, Week 4\n",
      "✓ SUCCESS! Team 5, Week 5\n",
      "✓ SUCCESS! Team 5, Week 6\n",
      "✓ SUCCESS! Team 5, Week 7\n",
      "✓ SUCCESS! Team 5, Week 8\n",
      "\n",
      "======================================================================\n",
      "Testing Team 6 (b\"Jontay's Jalebi\")\n",
      "======================================================================\n",
      "✓ SUCCESS! Team 6, Week current\n",
      "✓ SUCCESS! Team 6, Week 1\n",
      "✓ SUCCESS! Team 6, Week 2\n",
      "✓ SUCCESS! Team 6, Week 3\n",
      "✓ SUCCESS! Team 6, Week 4\n",
      "✓ SUCCESS! Team 6, Week 5\n",
      "✓ SUCCESS! Team 6, Week 6\n",
      "✓ SUCCESS! Team 6, Week 7\n",
      "✓ SUCCESS! Team 6, Week 8\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "✓ Found 54 successful combinations:\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week current\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 1\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 2\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 3\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 4\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 5\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 6\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 7\n",
      "  Team 1 (b'Cunning Ham Jerky'), Week 8\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week current\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 1\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 2\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 3\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 4\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 5\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 6\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 7\n",
      "  Team 2 (b\"Luka's LeGOAT Cheese Puffs\"), Week 8\n",
      "  Team 3 (b'The Banana Splitters'), Week current\n",
      "  Team 3 (b'The Banana Splitters'), Week 1\n",
      "  Team 3 (b'The Banana Splitters'), Week 2\n",
      "  Team 3 (b'The Banana Splitters'), Week 3\n",
      "  Team 3 (b'The Banana Splitters'), Week 4\n",
      "  Team 3 (b'The Banana Splitters'), Week 5\n",
      "  Team 3 (b'The Banana Splitters'), Week 6\n",
      "  Team 3 (b'The Banana Splitters'), Week 7\n",
      "  Team 3 (b'The Banana Splitters'), Week 8\n",
      "  Team 4 (b'Trust the Tiramisu'), Week current\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 1\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 2\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 3\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 4\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 5\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 6\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 7\n",
      "  Team 4 (b'Trust the Tiramisu'), Week 8\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week current\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 1\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 2\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 3\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 4\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 5\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 6\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 7\n",
      "  Team 5 (b'Dwane(Pound) the rock (Cake)sy'), Week 8\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week current\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 1\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 2\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 3\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 4\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 5\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 6\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 7\n",
      "  Team 6 (b\"Jontay's Jalebi\"), Week 8\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test get_team_stats_by_week with MULTIPLE teams and weeks\n",
    "# First, get all teams in the league\n",
    "\n",
    "POINTS_LEAGUE_ID = 229522 \n",
    "\n",
    "query = YahooFantasySportsQuery(\n",
    "    league_id=POINTS_LEAGUE_ID,\n",
    "    game_code=\"nba\",\n",
    "    game_id= GAME_ID,\n",
    "    env_var_fallback = True,\n",
    "    env_file_location = env_file_location,\n",
    "    save_token_data_to_env_file = True,\n",
    ")\n",
    "\n",
    "print(f\"Testing with {LEAGUE_TYPE} league (ID: {YAHOO_LEAGUE_ID})\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Step 1: Getting all teams in the league...\")\n",
    "print(\"=\" * 70)\n",
    "try:\n",
    "    teams = query.get_league_teams()\n",
    "    print(f\"✓ Found {len(teams)} teams\")\n",
    "    \n",
    "    # Extract team IDs and names\n",
    "    team_info = []\n",
    "    for team in teams:\n",
    "        try:\n",
    "            team_id = team.team_id\n",
    "            team_name = getattr(team, 'name', f'Team {team_id}')\n",
    "            team_info.append((team_id, team_name))\n",
    "            print(f\"  Team {team_id}: {team_name}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\nFound {len(team_info)} teams to test\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error getting teams: {e}\")\n",
    "    # Fallback to testing team IDs 1-12\n",
    "    team_info = [(i, f\"Team {i}\") for i in range(1, 13)]\n",
    "    print(f\"Using fallback team IDs: {[t[0] for t in team_info]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 2: Testing get_team_stats_by_week for different teams and weeks\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "weeks_to_test = [\"current\", 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "successful_combinations = []\n",
    "\n",
    "# Test first 6 teams with all weeks\n",
    "teams_to_test = team_info[:6] if len(team_info) >= 6 else team_info\n",
    "\n",
    "for team_id, team_name in teams_to_test:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing Team {team_id} ({team_name})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for week in weeks_to_test:\n",
    "        try:\n",
    "            data = query.get_team_stats_by_week(team_id, week)\n",
    "            print(f\"✓ SUCCESS! Team {team_id}, Week {week}\")\n",
    "            successful_combinations.append((team_id, team_name, week))\n",
    "            \n",
    "            # Check what fields are available\n",
    "            if hasattr(data, '__dict__'):\n",
    "                data_dict = data.__dict__\n",
    "                fields = list(data_dict.keys())\n",
    "                print(f\"  Fields: {fields}\")\n",
    "                \n",
    "                # Check for key fields\n",
    "                if 'team_projected_points' in fields or hasattr(data, 'team_projected_points'):\n",
    "                    print(f\"  ✓ team_projected_points EXISTS!\")\n",
    "                    try:\n",
    "                        val = data.team_projected_points if hasattr(data, 'team_projected_points') else data_dict.get('team_projected_points')\n",
    "                        print(f\"    Value: {val}\")\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    print(f\"  ✗ team_projected_points does NOT exist\")\n",
    "                \n",
    "                if 'team_points' in fields or hasattr(data, 'team_points'):\n",
    "                    print(f\"  ✓ team_points EXISTS!\")\n",
    "                    try:\n",
    "                        val = data.team_points if hasattr(data, 'team_points') else data_dict.get('team_points')\n",
    "                        print(f\"    Value: {val}\")\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    print(f\"  ✗ team_points does NOT exist\")\n",
    "                    \n",
    "        except KeyError as e:\n",
    "            # Only print if it's not the expected team_projected_points error\n",
    "            if 'team_projected_points' not in str(e):\n",
    "                print(f\"  ✗ KeyError (unexpected): {e}\")\n",
    "        except Exception as e:\n",
    "            # Only print unexpected errors\n",
    "            if 'team_projected_points' not in str(e):\n",
    "                print(f\"  ✗ Error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "if successful_combinations:\n",
    "    print(f\"✓ Found {len(successful_combinations)} successful combinations:\")\n",
    "    for team_id, team_name, week in successful_combinations:\n",
    "        print(f\"  Team {team_id} ({team_name}), Week {week}\")\n",
    "else:\n",
    "    print(\"✗ No successful combinations found - all failed with KeyError for team_projected_points\")\n",
    "    print(\"\\nThis suggests the yfpy library expects team_projected_points but the API\")\n",
    "    print(\"doesn't always return it. We may need to handle this differently.\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "811994a0",
   "metadata": {},
   "source": [
    "#### 2. Connecting LangChain Agent to Yahoo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f78e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c072b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat YahooFantasy Agent\n",
    "class YahooFantasyAgent:\n",
    "    def __init__(self):\n",
    "        self.YAHOO_CONSUMER_KEY = os.environ.get('YAHOO_CLIENT_ID', \"<INSERT_>\")\n",
    "        self.YAHOO_CONSUMER_SECRET = os.environ.get('YAHOO_CLIENT_SECRET', \"<INSERT>\")\n",
    "        self.YAHOO_LEAGUE_ID = 58930\n",
    "        self.GAME_CODE = \"nba\"\n",
    "        self.GAME_ID=466\n",
    "\n",
    "        self.query = YahooFantasySportsQuery(\n",
    "            league_id=YAHOO_LEAGUE_ID,\n",
    "            game_code=\"nba\",\n",
    "            game_id= GAME_ID,\n",
    "            yahoo_consumer_key = YAHOO_CONSUMER_KEY,\n",
    "            yahoo_consumer_secret = YAHOO_CONSUMER_SECRET,\n",
    "            env_var_fallback = True,\n",
    "            env_file_location = env_file_location,\n",
    "            save_token_data_to_env_file = True,\n",
    "        )\n",
    "\n",
    "    def get_league_metadata(self) -> str:\n",
    "        \"\"\"Fetch Yahoo Fantasy league metadata.\"\"\"\n",
    "        try:\n",
    "            data = self.query.get_league_metadata()\n",
    "            return f'The Yahoo Fantasy league metadata in json format is: {data}'\n",
    "        except Exception as e:\n",
    "            return f\"Failed to Yahoo Fantasy league metadata: {e}\"\n",
    "        \n",
    "@tool(\"YahooLeagueMetDataTool\", description=\"Get Yahoo League Metadata in json format from YPFS.\")\n",
    "def league_metadata_tool() -> str:\n",
    "    \"\"\"Get Yahoo League Metadata.\"\"\"\n",
    "    return YahooFantasyAgent().get_league_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96dbc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Clutch AI Agent\n",
    "tools = [league_metadata_tool]\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "agent_v1 = create_agent(\n",
    "    model = llm,\n",
    "    tools = tools,\n",
    "    system_prompt=\"You are a helpful assistant for a Yahoo Fantasy Sports league manager.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dc6e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the Yahoo Fantasy League Name?', additional_kwargs={}, response_metadata={}, id='0732860d-244f-44b6-bb5b-990cde41b7fd'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 67, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ0IjtiHWHr1QUjJ9LQkNGMwmbpjw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--18b03830-37ba-4409-9e68-ba2a49edd970-0', tool_calls=[{'name': 'YahooLeagueMetDataTool', 'args': {}, 'id': 'call_f7fLzHxSdQMlnYp2iy0Izota', 'type': 'tool_call'}], usage_metadata={'input_tokens': 67, 'output_tokens': 14, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='The Yahoo Fantasy league metadata in json format is: League({\\n  \"allow_add_to_dl_extra_pos\": 1,\\n  \"current_week\": 3,\\n  \"draft_status\": \"postdraft\",\\n  \"edit_key\": \"2025-11-06\",\\n  \"end_date\": \"2026-04-05\",\\n  \"end_week\": 23,\\n  \"felo_tier\": \"gold\",\\n  \"game_code\": \"nba\",\\n  \"iris_group_chat_id\": null,\\n  \"is_cash_league\": 0,\\n  \"is_highscore\": false,\\n  \"is_plus_league\": 0,\\n  \"is_pro_league\": 0,\\n  \"league_id\": \"58930\",\\n  \"league_key\": \"466.l.58930\",\\n  \"league_type\": \"private\",\\n  \"league_update_timestamp\": 1762418787,\\n  \"logo_url\": \"https://yahoofantasysports-res.cloudinary.com/image/upload/t_s192sq/fantasy-logos/56479288575_ec9899.jpg\",\\n  \"matchup_week\": 3,\\n  \"name\": \"TK Fiji Fantasy 2024/25\",\\n  \"num_teams\": 12,\\n  \"renew\": \"454_14696\",\\n  \"renewed\": null,\\n  \"roster_type\": \"date\",\\n  \"scoring_type\": \"headone\",\\n  \"season\": 2025,\\n  \"start_date\": \"2025-10-21\",\\n  \"start_week\": 1,\\n  \"url\": \"https://basketball.fantasysports.yahoo.com/nba/58930\",\\n  \"weekly_deadline\": \"intraday\"\\n})', name='YahooLeagueMetDataTool', id='6b4d251c-47c1-4d80-aebb-7d3f579ea38b', tool_call_id='call_f7fLzHxSdQMlnYp2iy0Izota'),\n",
       "  AIMessage(content='The Yahoo Fantasy League Name is **TK Fiji Fantasy 2024/25**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 441, 'total_tokens': 459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ0ImXxJskyJaXGAnPwkBUQoAjjj3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--021c7c31-54bd-47bb-b0e4-c985ef5c1139-0', usage_metadata={'input_tokens': 441, 'output_tokens': 18, 'total_tokens': 459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Agent\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What is the Yahoo Fantasy League Name?\"}]}\n",
    "agent_v1.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5e35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 67, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ0InZoXDaWA6cD3N7JF8JVvk7cxZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--cd9a3d43-8692-4d8c-b5bb-26d49cbdca8f-0', tool_calls=[{'name': 'YahooLeagueMetDataTool', 'args': {}, 'id': 'call_G0vPVyZnLHGxuGZIPo2clSPw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 67, 'output_tokens': 14, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='The Yahoo Fantasy league metadata in json format is: League({\\n  \"allow_add_to_dl_extra_pos\": 1,\\n  \"current_week\": 3,\\n  \"draft_status\": \"postdraft\",\\n  \"edit_key\": \"2025-11-06\",\\n  \"end_date\": \"2026-04-05\",\\n  \"end_week\": 23,\\n  \"felo_tier\": \"gold\",\\n  \"game_code\": \"nba\",\\n  \"iris_group_chat_id\": null,\\n  \"is_cash_league\": 0,\\n  \"is_highscore\": false,\\n  \"is_plus_league\": 0,\\n  \"is_pro_league\": 0,\\n  \"league_id\": \"58930\",\\n  \"league_key\": \"466.l.58930\",\\n  \"league_type\": \"private\",\\n  \"league_update_timestamp\": 1762418787,\\n  \"logo_url\": \"https://yahoofantasysports-res.cloudinary.com/image/upload/t_s192sq/fantasy-logos/56479288575_ec9899.jpg\",\\n  \"matchup_week\": 3,\\n  \"name\": \"TK Fiji Fantasy 2024/25\",\\n  \"num_teams\": 12,\\n  \"renew\": \"454_14696\",\\n  \"renewed\": null,\\n  \"roster_type\": \"date\",\\n  \"scoring_type\": \"headone\",\\n  \"season\": 2025,\\n  \"start_date\": \"2025-10-21\",\\n  \"start_week\": 1,\\n  \"url\": \"https://basketball.fantasysports.yahoo.com/nba/58930\",\\n  \"weekly_deadline\": \"intraday\"\\n})', name='YahooLeagueMetDataTool', id='fa607da3-2cc4-4c4b-89ae-2d73c9e16387', tool_call_id='call_G0vPVyZnLHGxuGZIPo2clSPw')]}}\n",
      "{'model': {'messages': [AIMessage(content='The Yahoo Fantasy League Name is **TK Fiji Fantasy 2024/25**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 441, 'total_tokens': 459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ0IpHpxTGo4s7NHtpl8EAWpW38o8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8d8c361c-ac34-4088-8022-3072727c74cb-0', usage_metadata={'input_tokens': 441, 'output_tokens': 18, 'total_tokens': 459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "#Stream Agent Response for Debug\n",
    "for event in agent_v1.stream(inputs):\n",
    "    print(event)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf5b41c8",
   "metadata": {},
   "source": [
    "#### 2. Adding Youtube Transcripts to VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da169c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5949e280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.youtube.com/watch?v=TB2QwCRMams&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}, page_content=\"There are a lot of players who are either hurt, injury-prone, susceptible to tanking. So, what do you do in a fantasy draft? When do you take them? Michael Bolton, he's going to give you some answers. >> Thanks, Josh. It's Michael Bolton here, and it's time for another episode of the Locked On Fantasy Basketball Podcast. Let's get to it. >> Let's get to it. Indeed. You are Locked on Fantasy, your daily\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Documents from YouTube\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=TB2QwCRMams&t=2s\", \n",
    "    add_video_info=False,\n",
    "    transcript_format=TranscriptFormat.CHUNKS,\n",
    "    chunk_size_seconds=30\n",
    ")\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d829effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding YouTube Documents\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "@tool(\"locked_on_retreiver\", description=\"Retrieve contextual knowledge from Locked On Basketball.\")\n",
    "def retrieve_LockedOnKnowledge(query: str) -> str:\n",
    "    \"\"\"Retrieve contextual knowledge from Locked On Podcast YouTube transcripts or articles.\"\"\"\n",
    "    results = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([r.page_content for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d3d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ReACT Agent with YouTube Knowledge Retrieval and Yahoo Fantasy Tool\n",
    "#Note: Temperature is a parameter that controls the “creativity” or randomness of the text generated.\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [league_metadata_tool, retrieve_LockedOnKnowledge]\n",
    "\n",
    "agent_v2 = create_agent(\n",
    "    model = llm,\n",
    "    tools = tools,\n",
    "    system_prompt=\"You are a helpful assistant for a Yahoo Fantasy Sports league manager.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55e210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Agent\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"Give me 3 key draft advice from Locked On Podcast that I should follow for my league.\"}]}\n",
    "output_v2 = agent_v2.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6530bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ccc72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Give me 3 key draft advice from Locked On Podcast that I should follow for my league. Provide sources.', additional_kwargs={}, response_metadata={}, id='d75e4a65-1991-40ca-9787-cd5948ca70c5'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 106, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ2mschdYzSy3zkJ20O9sVsFZdmg3', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--35ccf9ce-2f13-435b-ab6f-eeac204a8b74-0', tool_calls=[{'name': 'locked_on_retreiver', 'args': {'query': 'draft advice'}, 'id': 'call_3E8rKbt8Z0I1EEjjVlUgTJYN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 106, 'output_tokens': 19, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"and you draft off it. Well done. Right? But it's actually suboptimal that doesn't provide good results. I would never draft off that. So why would I want somebody else to do it that way? It's about having little groupings and and ideas and flexibilities and guys that you can sort, oh, I'll do this this time and maybe I'll do this. But in the end, when you're getting down to nitty-gritty decisions like that, the differences aren't that big. And the same goes with this sort of stuff. I'd never draft this guy, would you? No. Well, what if he sits there at pick 90\\n\\nlook at his live uh player props. Maybe we check the spread. Maybe we do a a same game parlay for the next upcoming game. Or we look at futures across the NBA. So, what are you waiting for? Go to fanul.com, download the FanDuel app today, and get started. And don't forget to gamble responsibly. We're talking about when and where to draft injured players or guys that we're worried about heading into the season. You might have different answers for these guys and that is totally okay. I'm just giving you some of my thoughts as to where we draft these guys. Now,\\n\\nsome more injuryprone or injured players or what we're doing in the drafts with them. Today's episode though, it is brought to you by Wayfair. The holidays, they're going to be here before you know it. Maybe the holidays are here before LeBron is back, but that's exciting. Um, you got to get your homes ready though. People to come over, events to host, but you've got everything in order. Have you got your beds sorted, your linens, your beddings, your silverware, serving wear, table wear, whatever wear. Have you got it all? Cuz Wayfair can do it at any style and any budget. Wayfair has all the things that you need to personalize\\n\\nPzinga sits at the moment in terms of um where he's going to be drafted like you can get 40s, 50s sometimes to get Pzingers and like the the and so much of this stuff with these injury-prone discount players, it's about like the value becomes too hard to pass up at certain spots. So, I'm just trying to see what puzzling's ADP is. It's 54. Like, it's 63 on fan tracks and 77 on ESPN. They are no-brainer decisions to me. Damonte\", name='locked_on_retreiver', id='1c7c4fc1-5999-42b1-8b9e-7baf3e2fb0d7', tool_call_id='call_3E8rKbt8Z0I1EEjjVlUgTJYN'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 648, 'total_tokens': 669, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ2mwzUGtgmIM5LNfdWrzP9lGHv5b', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--c21be7f9-fe74-42e8-aa7e-89ad0fc03f7c-0', tool_calls=[{'name': 'locked_on_retreiver', 'args': {'query': 'fantasy draft strategy'}, 'id': 'call_meVsOH6U39hVtJsr9yjxrpJV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 648, 'output_tokens': 21, 'total_tokens': 669, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"and you draft off it. Well done. Right? But it's actually suboptimal that doesn't provide good results. I would never draft off that. So why would I want somebody else to do it that way? It's about having little groupings and and ideas and flexibilities and guys that you can sort, oh, I'll do this this time and maybe I'll do this. But in the end, when you're getting down to nitty-gritty decisions like that, the differences aren't that big. And the same goes with this sort of stuff. I'd never draft this guy, would you? No. Well, what if he sits there at pick 90\\n\\nThere are a lot of players who are either hurt, injury-prone, susceptible to tanking. So, what do you do in a fantasy draft? When do you take them? Michael Bolton, he's going to give you some answers. >> Thanks, Josh. It's Michael Bolton here, and it's time for another episode of the Locked On Fantasy Basketball Podcast. Let's get to it. >> Let's get to it. Indeed. You are Locked on Fantasy, your daily\\n\\nbonus bets to use across the app. Head to fangel.com to get started. Thank you also for making Locked on Fantasy Basketball your first listen every day. We are free. We are available on all platforms. So, what are we talking about? Injured players. There are different categorizations here. Like I've said, there are players who literally are currently injured. There are players who you think are going to get injured. There are players that we worry about when they're going to be available on tanking teams and how often they're going to play. So, I have got 30 plus names I'm going to talk about here.\\n\\nhamstring. I probably wouldn't take him in round two in category leagues. Points league is debatable. Now, I'm looking outside the top 30 and honestly might go lower. Maybe it's not that like missing a week of time is a huge deal. It's one week out of let's say 21 weeks before your fantasy playoffs or before your fantasy season ends. Whatever it is, it's not a big deal. It's more that that can linger and we have seen it time and time and\", name='locked_on_retreiver', id='7b7e8c7d-b52b-4c35-bab8-b3ba0a3e9d65', tool_call_id='call_meVsOH6U39hVtJsr9yjxrpJV'), AIMessage(content='Here are three key pieces of draft advice from the Locked On Podcast that you should consider for your league:\\n\\n1. **Prioritize Value Over Rank**: Drafting based solely on rankings can lead to suboptimal results. Instead, create flexible groupings of players based on value and potential. When you\\'re making decisions, don\\'t just stick to the rankings—consider who is available and weigh the value against the risk associated with each player. This approach allows you to adapt during the draft and seize opportunities that arise.\\n\\n2. **Be Creative with Injured Players**: It\\'s important to have a strategy for drafting players who are currently injured or prone to injuries. Consider their average draft position (ADP) and weigh the potential returns against the risks. Sometimes, the discounts on players who may start the season on the sidelines are too good to ignore, especially if they can be strong contributors when healthy. Tailor your approach based on the severity of the injury and the player\\'s overall potential impact.\\n\\n3. **Utilize Groupings and Flexibility**: Instead of arriving with a strict \"do not draft\" list, categorize players into groups with various strategies. This allows you to maintain flexibility in your draft decisions. For example, if a highly rated player falls significantly, be prepared to reassess your strategy and potentially take them if the value is compelling. The differences among players at the same tier may not be substantial, so use this knowledge to adapt your draft strategy dynamically.\\n\\nThese insights emphasize the importance of adapting to the evolving landscape of the draft and making tactical decisions based on player value rather than sticking rigidly to predetermined rankings.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 324, 'prompt_tokens': 1131, 'total_tokens': 1455, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CZ2mzLanOGbWMmjLltBiaVViHdgcI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4f7f1e85-bc32-4d13-8e6d-84a02b3892d1-0', usage_metadata={'input_tokens': 1131, 'output_tokens': 324, 'total_tokens': 1455, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "print(output_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b49f1a",
   "metadata": {},
   "source": [
    "#### 3. Add Tabular Data from Basketball Monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e77362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Basketball Monster player rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/thknvx0947g32l8bwlv764rc0000gn/T/ipykernel_68721/1322363733.py:24: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully parsed table with 203 rows using pandas\n",
      "\n",
      "Table shape: (203, 30)\n",
      "\n",
      "Data types:\n",
      "Scraping Hastag Monster player rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/thknvx0947g32l8bwlv764rc0000gn/T/ipykernel_68721/1322363733.py:24: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully parsed table with 1 rows using pandas\n",
      "\n",
      "Table shape: (1, 6)\n",
      "\n",
      "Data types:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# Scrape the Basketball Monster player rankings table\n",
    "def scrape_dashboard_tables(url):\n",
    "    \"\"\"\n",
    "    Scrape player rankings table from Basketball Monster.\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with player rankings data\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Fetch the page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Try using pandas read_html first (easiest method)\n",
    "        try:\n",
    "            tables = pd.read_html(response.text)\n",
    "            if tables:\n",
    "                df = tables[0]  # Usually the first table is the main rankings\n",
    "                print(f\"✓ Successfully parsed table with {len(df)} rows using pandas\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(f\"pandas read_html failed: {e}, trying manual parsing...\")\n",
    "        \n",
    "        # Fallback: Manual parsing with scrapy selector\n",
    "        selector = Selector(text=response.text)\n",
    "        \n",
    "        # Find the rankings table\n",
    "        table = selector.css('table').get()\n",
    "        if table:\n",
    "            # Try to parse with pandas again on the extracted table HTML\n",
    "            df = pd.read_html(table)[0]\n",
    "            print(f\"✓ Successfully parsed table with {len(df)} rows using manual extraction\")\n",
    "            return df\n",
    "        else:\n",
    "            print(\"✗ Could not find rankings table in HTML\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error scraping table: {e}\")\n",
    "        return None\n",
    "\n",
    "# Scrape the Basketball Monster Rankings\n",
    "print(\"Scraping Basketball Monster player rankings...\")\n",
    "url = 'https://basketballmonster.com/playerrankings.aspx'\n",
    "basketball_monster_rankings_df = scrape_dashboard_tables(url)\n",
    "\n",
    "if basketball_monster_rankings_df is not None:\n",
    "    print(f\"\\nTable shape: {basketball_monster_rankings_df.shape}\")\n",
    "    print(f\"\\nData types:\")\n",
    "else:\n",
    "    print(\"Failed to scrape rankings table\")\n",
    "\n",
    "# Scrape the Hashtag Basketball Rankings\n",
    "print(\"Scraping Hastag Monster player rankings...\")\n",
    "url = 'https://hashtagbasketball.com/fantasy-basketball-dynasty-rankings'\n",
    "hashtag_rankings_df = scrape_dashboard_tables(url)\n",
    "\n",
    "if hashtag_rankings_df is not None:\n",
    "    print(f\"\\nTable shape: {hashtag_rankings_df.shape}\")\n",
    "    print(f\"\\nData types:\")\n",
    "else:\n",
    "    print(\"Failed to scrape rankings table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f66f8848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SET OF RANKINGS</th>\n",
       "      <th>FORECAST RANGE</th>\n",
       "      <th>STATS FROM</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>FROM</th>\n",
       "      <th>NBA TEAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall  Contending  Rebuilding  Rookies  Poin...</td>\n",
       "      <td>Next 5 seasons  Next 3 seasons</td>\n",
       "      <td>2025-26 Regular Season</td>\n",
       "      <td>All  PG  SG  SF  PF  C</td>\n",
       "      <td>Yahoo  Fantrax</td>\n",
       "      <td>All Teams  Atlanta Hawks  Boston Celtics  Broo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     SET OF RANKINGS  \\\n",
       "0  Overall  Contending  Rebuilding  Rookies  Poin...   \n",
       "\n",
       "                   FORECAST RANGE              STATS FROM  \\\n",
       "0  Next 5 seasons  Next 3 seasons  2025-26 Regular Season   \n",
       "\n",
       "                 POSITION            FROM  \\\n",
       "0  All  PG  SG  SF  PF  C  Yahoo  Fantrax   \n",
       "\n",
       "                                            NBA TEAM  \n",
       "0  All Teams  Atlanta Hawks  Boston Celtics  Broo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_rankings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dc0556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHOW</th>\n",
       "      <th>MIN GP</th>\n",
       "      <th>Z SCORE</th>\n",
       "      <th>CO%</th>\n",
       "      <th>AGE</th>\n",
       "      <th>POSITION</th>\n",
       "      <th>POS FROM</th>\n",
       "      <th>NBA TEAM</th>\n",
       "      <th>DATA AND RANKINGS FROM</th>\n",
       "      <th>BASED ON</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top 30  50  100  Top 200  300  400  All</td>\n",
       "      <td>1  2  3  5  10  15  20</td>\n",
       "      <td>On  Off</td>\n",
       "      <td>On  Off</td>\n",
       "      <td>On  Off</td>\n",
       "      <td>All  PG  SG  SF  PF  C</td>\n",
       "      <td>Yahoo  ESPN  Fantrax  Depth Chart</td>\n",
       "      <td>All  ATL  BKN  BOS  CHA  CHI  CLE  DAL  DEN  D...</td>\n",
       "      <td>2025-26 Rest of Season Rankings (Projections u...</td>\n",
       "      <td>Total  Averages</td>\n",
       "      <td>Standard  H2H  Minus 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SHOW                  MIN GP  Z SCORE  \\\n",
       "0  Top 30  50  100  Top 200  300  400  All  1  2  3  5  10  15  20  On  Off   \n",
       "\n",
       "       CO%      AGE                POSITION  \\\n",
       "0  On  Off  On  Off  All  PG  SG  SF  PF  C   \n",
       "\n",
       "                            POS FROM  \\\n",
       "0  Yahoo  ESPN  Fantrax  Depth Chart   \n",
       "\n",
       "                                            NBA TEAM  \\\n",
       "0  All  ATL  BKN  BOS  CHA  CHI  CLE  DAL  DEN  D...   \n",
       "\n",
       "                              DATA AND RANKINGS FROM         BASED ON  \\\n",
       "0  2025-26 Rest of Season Rankings (Projections u...  Total  Averages   \n",
       "\n",
       "                     TYPE  \n",
       "0  Standard  H2H  Minus 1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_rankings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c57fffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Value</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Inj</th>\n",
       "      <th>g</th>\n",
       "      <th>m/g</th>\n",
       "      <th>p/g</th>\n",
       "      <th>...</th>\n",
       "      <th>USG</th>\n",
       "      <th>pV</th>\n",
       "      <th>3V</th>\n",
       "      <th>rV</th>\n",
       "      <th>aV</th>\n",
       "      <th>sV</th>\n",
       "      <th>bV</th>\n",
       "      <th>fg%V</th>\n",
       "      <th>ft%V</th>\n",
       "      <th>toV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>DEN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>34.5</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.97</td>\n",
       "      <td>Victor Wembanyama</td>\n",
       "      <td>SAS</td>\n",
       "      <td>C</td>\n",
       "      <td>INJ 10g</td>\n",
       "      <td>12</td>\n",
       "      <td>34.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1.48</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Shai Gilgeous-Alexander</td>\n",
       "      <td>OKC</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>LAC</td>\n",
       "      <td>F</td>\n",
       "      <td>INJ 5g</td>\n",
       "      <td>6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>...</td>\n",
       "      <td>28.3</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.15</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Tyrese Maxey</td>\n",
       "      <td>PHI</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "      <td>14</td>\n",
       "      <td>40.3</td>\n",
       "      <td>31.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Round Rank Value                     Name Team Pos      Inj   g   m/g   p/g  \\\n",
       "0     1    1  1.34             Nikola Jokic  DEN   C      NaN  14  34.5  29.1   \n",
       "1     1    2  0.97        Victor Wembanyama  SAS   C  INJ 10g  12  34.7  26.2   \n",
       "2     1    3  0.92  Shai Gilgeous-Alexander  OKC   G      NaN  16  33.4  32.0   \n",
       "3     1    4  0.77            Kawhi Leonard  LAC   F   INJ 5g   6  33.5  24.3   \n",
       "4     1    5  0.76             Tyrese Maxey  PHI   G        P  14  40.3  31.9   \n",
       "\n",
       "   ...   USG    pV     3V     rV     aV     sV     bV   fg%V  ft%V    toV  \n",
       "0  ...  28.6  1.95   0.11   2.91   3.48   1.22   0.20   3.26  0.78  -1.86  \n",
       "1  ...  30.9  1.48  -0.07   2.80   0.20  -0.03   5.16   0.25  0.84  -1.87  \n",
       "2  ...  33.8  2.41   0.43  -0.31   1.35   0.90   0.36   0.98  2.02   0.14  \n",
       "3  ...  28.3  1.19   0.57  -0.05  -0.03   3.15  -0.01   0.30  1.71   0.11  \n",
       "4  ...  30.1  2.40   2.10  -0.42   1.94   0.90   0.20  -0.91  1.40  -0.80  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    print(f\"\\nFirst few rows:\")\n",
    "    rankings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b61fa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing Basketball Monster rankings WITH punt categories\n",
      "============================================================\n",
      "\n",
      "1. Fetching default rankings (no punt categories):\n",
      "✓ Successfully parsed table with 203 rows using pandas\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Fetching rankings with punt categories: ['FT%', 'TO']\n",
      "Fetching rankings with punt categories: ['FT%', 'TO']\n",
      "URL: https://basketballmonster.com/playerrankings.aspx?Punt=FT%25%2CTO\n",
      "✓ Successfully parsed table with 203 rows using pandas\n",
      "  Punt categories applied: ['FT%', 'TO']\n"
     ]
    }
   ],
   "source": [
    "# Enhanced version with punt categories support\n",
    "from urllib.parse import urlencode, urlparse, urlunparse\n",
    "from io import StringIO\n",
    "\n",
    "def scrape_basketball_monster_rankings_with_punt(base_url, punt_categories=None):\n",
    "    \"\"\"\n",
    "    Scrape player rankings table from Basketball Monster with optional punt categories.\n",
    "    \n",
    "    Args:\n",
    "        base_url: Base URL for Basketball Monster rankings (e.g., 'https://basketballmonster.com/playerrankings.aspx')\n",
    "        punt_categories: List of categories to punt (e.g., ['FT%', 'TO', 'FG%'])\n",
    "            Common categories: 'PTS', 'REB', 'AST', 'STL', 'BLK', '3PM', 'FG%', 'FT%', 'TO'\n",
    "            Note: Category names should match Basketball Monster's format exactly\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with player rankings data\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Build URL with punt categories if provided\n",
    "    url = base_url\n",
    "    if punt_categories and len(punt_categories) > 0:\n",
    "        # Join categories with comma and URL encode if needed\n",
    "        punt_str = ','.join(str(cat) for cat in punt_categories)\n",
    "        parsed_url = urlparse(base_url)\n",
    "        query_params = urlencode({'Punt': punt_str})\n",
    "        url = urlunparse((\n",
    "            parsed_url.scheme,\n",
    "            parsed_url.netloc,\n",
    "            parsed_url.path,\n",
    "            parsed_url.params,\n",
    "            query_params,\n",
    "            parsed_url.fragment\n",
    "        ))\n",
    "        print(f\"Fetching rankings with punt categories: {punt_categories}\")\n",
    "        print(f\"URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Fetch the page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Try using pandas read_html first (easiest method)\n",
    "        try:\n",
    "            tables = pd.read_html(StringIO(response.text))\n",
    "            if tables:\n",
    "                df = tables[0]  # Usually the first table is the main rankings\n",
    "                print(f\"✓ Successfully parsed table with {len(df)} rows using pandas\")\n",
    "                if punt_categories:\n",
    "                    print(f\"  Punt categories applied: {punt_categories}\")\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(f\"pandas read_html failed: {e}, trying manual parsing...\")\n",
    "        \n",
    "        # Fallback: Manual parsing with scrapy selector\n",
    "        selector = Selector(text=response.text)\n",
    "        \n",
    "        # Find the rankings table\n",
    "        table = selector.css('table').get()\n",
    "        if table:\n",
    "            # Try to parse with pandas again on the extracted table HTML\n",
    "            df = pd.read_html(StringIO(table))[0]\n",
    "            print(f\"✓ Successfully parsed table with {len(df)} rows using manual extraction\")\n",
    "            if punt_categories:\n",
    "                print(f\"  Punt categories applied: {punt_categories}\")\n",
    "            return df\n",
    "        else:\n",
    "            print(\"✗ Could not find rankings table in HTML\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error scraping table: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Test with punt categories\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Basketball Monster rankings WITH punt categories\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "base_url = 'https://basketballmonster.com/playerrankings.aspx'\n",
    "\n",
    "# Test 1: No punt categories (default rankings)\n",
    "print(\"\\n1. Fetching default rankings (no punt categories):\")\n",
    "df_default = scrape_basketball_monster_rankings_with_punt(base_url, punt_categories=None)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "\n",
    "# Test 2: With punt categories (FT% and TO)\n",
    "print(\"\\n2. Fetching rankings with punt categories: ['FT%', 'TO']\")\n",
    "df_punt_ft_to = scrape_basketball_monster_rankings_with_punt(base_url, punt_categories=['FT%', 'TO'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c871eda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Round', 'Rank', 'Value', 'Name', 'Team', 'Pos', 'Inj', 'g', 'm/g',\n",
       "       'p/g', '3/g', 'r/g', 'a/g', 's/g', 'b/g', 'fg%', 'fga/g', 'ft%',\n",
       "       'fta/g', 'to/g', 'USG', 'pV', '3V', 'rV', 'aV', 'sV', 'bV', 'fg%V',\n",
       "       'ft%V', 'toV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0306690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Value</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Inj</th>\n",
       "      <th>g</th>\n",
       "      <th>m/g</th>\n",
       "      <th>p/g</th>\n",
       "      <th>...</th>\n",
       "      <th>USG</th>\n",
       "      <th>pV</th>\n",
       "      <th>3V</th>\n",
       "      <th>rV</th>\n",
       "      <th>aV</th>\n",
       "      <th>sV</th>\n",
       "      <th>bV</th>\n",
       "      <th>fg%V</th>\n",
       "      <th>ft%V</th>\n",
       "      <th>toV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.35</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>DEN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>34.8</td>\n",
       "      <td>29.6</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Tyler Herro</td>\n",
       "      <td>MIA</td>\n",
       "      <td>G</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>30.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.03</td>\n",
       "      <td>Shai Gilgeous-Alexander</td>\n",
       "      <td>OKC</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>...</td>\n",
       "      <td>33.7</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Victor Wembanyama</td>\n",
       "      <td>SAS</td>\n",
       "      <td>C</td>\n",
       "      <td>INJ 7g</td>\n",
       "      <td>12</td>\n",
       "      <td>34.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Tyrese Maxey</td>\n",
       "      <td>PHI</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>39.9</td>\n",
       "      <td>32.2</td>\n",
       "      <td>...</td>\n",
       "      <td>30.3</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.13</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>16</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>Daniss Jenkins</td>\n",
       "      <td>DET</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>19.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>16</td>\n",
       "      <td>185</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>Dylan Harper</td>\n",
       "      <td>SAS</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>16</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>Vince Williams Jr.</td>\n",
       "      <td>MEM</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>16</td>\n",
       "      <td>187</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>T.J. McConnell</td>\n",
       "      <td>IND</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>10.3</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>16</td>\n",
       "      <td>188</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>Christian Braun</td>\n",
       "      <td>DEN</td>\n",
       "      <td>G</td>\n",
       "      <td>INJ 19g</td>\n",
       "      <td>11</td>\n",
       "      <td>29.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>...</td>\n",
       "      <td>16.2</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Round Rank  Value                     Name Team Pos      Inj   g   m/g  \\\n",
       "0       1    1   1.35             Nikola Jokic  DEN   C      NaN  17  34.8   \n",
       "1       1    2   1.04              Tyler Herro  MIA   G       IN   2  30.9   \n",
       "2       1    3   1.03  Shai Gilgeous-Alexander  OKC   G      NaN  19  33.2   \n",
       "3       1    4   1.01        Victor Wembanyama  SAS   C   INJ 7g  12  34.7   \n",
       "4       1    5   0.80             Tyrese Maxey  PHI   G      NaN  17  39.9   \n",
       "..    ...  ...    ...                      ...  ...  ..      ...  ..   ...   \n",
       "198    16  184  -0.40           Daniss Jenkins  DET   G      NaN  13  19.1   \n",
       "199    16  185  -0.40             Dylan Harper  SAS   G      NaN   7  22.4   \n",
       "200    16  186  -0.40       Vince Williams Jr.  MEM   G      NaN  14  22.2   \n",
       "201    16  187  -0.41           T.J. McConnell  IND   G      NaN   8  17.1   \n",
       "202    16  188  -0.41          Christian Braun  DEN   G  INJ 19g  11  29.6   \n",
       "\n",
       "      p/g  ...   USG     pV     3V     rV     aV     sV     bV   fg%V   ft%V  \\\n",
       "0    29.6  ...  29.0   2.02   0.37   2.75   3.46   1.17   0.15   3.11   0.83   \n",
       "1    26.5  ...  25.3   1.52  -0.22   0.06  -0.04   2.12  -0.35   3.20   1.99   \n",
       "2    32.6  ...  33.7   2.51   0.41  -0.38   1.39   1.15   0.19   1.50   2.26   \n",
       "3    26.2  ...  30.8   1.47  -0.06   2.78   0.19   0.01   5.39   0.27   0.91   \n",
       "4    32.2  ...  30.3   2.45   2.13  -0.57   1.83   1.17   0.25  -0.63   1.42   \n",
       "..    ...  ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "198  10.0  ...  21.3  -1.15  -0.55  -1.58   0.16   0.35  -1.13   0.18  -0.32   \n",
       "199  13.0  ...  25.0  -0.67  -0.84  -0.79   0.00  -0.51  -1.28  -0.27   0.31   \n",
       "200   7.9  ...  19.2  -1.49  -0.50  -0.31   0.95  -0.18  -0.61  -1.22   0.10   \n",
       "201  10.3  ...  25.0  -1.11  -1.06  -1.28   0.19  -0.47  -1.28   0.10   0.04   \n",
       "202  11.4  ...  16.2  -0.93  -1.14  -0.59  -0.31  -0.60  -0.77   0.03  -0.10   \n",
       "\n",
       "       toV  \n",
       "0    -1.72  \n",
       "1     1.06  \n",
       "2     0.23  \n",
       "3    -1.85  \n",
       "4    -0.86  \n",
       "..     ...  \n",
       "198   0.45  \n",
       "199   0.42  \n",
       "200  -0.39  \n",
       "201   1.20  \n",
       "202   0.75  \n",
       "\n",
       "[203 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa6aed",
   "metadata": {},
   "source": [
    "#### 4. NBA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd239b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import scoreboardv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798a518",
   "metadata": {},
   "source": [
    "#### 7. Add Articles to vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e710d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generic scraper with RotoWire...\n",
      "✓ Successfully scraped: How Does Fantasy Basketball Work: Best Tips for Your 2025 League\n",
      "  Source: www.rotowire.com\n",
      "  Content length: 10003 characters\n",
      "  Preview: Whether it's your first time playing fantasy sports or you're a seasoned fantasy football player looking for a new challenge, this guide aims to educate you about how to approach fantasy basketball. R...\n"
     ]
    }
   ],
   "source": [
    "# Generic web scraping function using scrapy selectors\n",
    "import requests\n",
    "from scrapy.selector import Selector\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "def scrape_article_content(url, max_content_length=10000):\n",
    "    \"\"\"\n",
    "    Generic function to scrape article content from any URL.\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to scrape (can be absolute or relative)\n",
    "        max_content_length: Maximum length of content to return (default: 10000)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'url', 'title', 'content', and 'source' keys, or None if error\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Parse and normalize URL\n",
    "        parsed_url = urlparse(url)\n",
    "        if not parsed_url.scheme:\n",
    "            # If no scheme, assume https\n",
    "            url = f\"https://{url}\"\n",
    "            parsed_url = urlparse(url)\n",
    "        elif not parsed_url.netloc:\n",
    "            # If relative URL, we need a base URL - return error\n",
    "            raise ValueError(f\"Invalid URL format: {url}\")\n",
    "        \n",
    "        # Get the domain for source tracking\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        # Fetch the page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        \n",
    "        # Parse with scrapy selector\n",
    "        selector = Selector(text=response.text)\n",
    "        \n",
    "        # Extract title - try multiple common patterns\n",
    "        title = None\n",
    "        title_selectors = [\n",
    "            'h1::text',\n",
    "            '.article-title::text',\n",
    "            '.post-title::text',\n",
    "            '.entry-title::text',\n",
    "            'title::text',\n",
    "            'meta[property=\"og:title\"]::attr(content)',\n",
    "            'meta[name=\"twitter:title\"]::attr(content)'\n",
    "        ]\n",
    "        \n",
    "        for selector_pattern in title_selectors:\n",
    "            title = selector.css(selector_pattern).get()\n",
    "            if title:\n",
    "                title = title.strip()\n",
    "                break\n",
    "        \n",
    "        # Fallback to page title tag\n",
    "        if not title:\n",
    "            title = selector.css('title::text').get()\n",
    "            if title:\n",
    "                # Clean up title (remove site name if present)\n",
    "                title = title.split('|')[0].split('-')[0].strip()\n",
    "        \n",
    "        title = title or 'Untitled'\n",
    "        \n",
    "        # Extract article content - try multiple common content selectors\n",
    "        content = None\n",
    "        content_selectors = [\n",
    "            'article p::text',\n",
    "            'article::text',\n",
    "            '.article-body p::text',\n",
    "            '.article-content p::text',\n",
    "            '.post-content p::text',\n",
    "            '.entry-content p::text',\n",
    "            '.content p::text',\n",
    "            'main article p::text',\n",
    "            'main p::text',\n",
    "            '[role=\"article\"] p::text'\n",
    "        ]\n",
    "        \n",
    "        for selector_pattern in content_selectors:\n",
    "            paragraphs = selector.css(selector_pattern).getall()\n",
    "            if paragraphs:\n",
    "                text_content = ' '.join([p.strip() for p in paragraphs if p.strip()])\n",
    "                if len(text_content) > 200:  # Only use if substantial content\n",
    "                    content = text_content\n",
    "                    break\n",
    "        \n",
    "        # Fallback: try to get text from main content areas\n",
    "        if not content:\n",
    "            main_content = selector.css('main, article, .main-content, .content').get()\n",
    "            if main_content:\n",
    "                main_selector = Selector(text=main_content)\n",
    "                content = ' '.join(main_selector.css('::text').getall())\n",
    "        \n",
    "        # Last resort: get all paragraph text from body\n",
    "        if not content:\n",
    "            # Use XPath to exclude common non-content elements\n",
    "            paragraphs = selector.xpath('//body//p[not(ancestor::script|ancestor::style|ancestor::nav|ancestor::header|ancestor::footer|ancestor::aside)]//text()').getall()\n",
    "            content = ' '.join([p.strip() for p in paragraphs if p.strip()])\n",
    "        \n",
    "        # Clean up content\n",
    "        if content:\n",
    "            content = ' '.join(content.split())  # Normalize whitespace\n",
    "            content = content.strip()\n",
    "        \n",
    "        if not content or len(content) < 50:\n",
    "            print(f\"Warning: Minimal or no content extracted from {url}\")\n",
    "            return None\n",
    "        \n",
    "        # Limit content length\n",
    "        if len(content) > max_content_length:\n",
    "            content = content[:max_content_length] + \"...\"\n",
    "        \n",
    "        return {\n",
    "            'url': url,\n",
    "            'title': title,\n",
    "            'content': content,\n",
    "            'source': domain\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function with RotoWire\n",
    "test_url = \"https://www.rotowire.com/basketball/advice/\"\n",
    "print(\"Testing generic scraper with RotoWire...\")\n",
    "test_article = scrape_article_content(test_url)\n",
    "if test_article:\n",
    "    print(f\"✓ Successfully scraped: {test_article['title']}\")\n",
    "    print(f\"  Source: {test_article['source']}\")\n",
    "    print(f\"  Content length: {len(test_article['content'])} characters\")\n",
    "    print(f\"  Preview: {test_article['content'][:200]}...\")\n",
    "else:\n",
    "    print(\"✗ Failed to scrape article\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d41d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Testing Hashtag Basketball Dynasty Rankings Scraping\n",
      "======================================================================\n",
      "\n",
      "1. Trying pandas read_html on all tables...\n",
      "   Found 2 table(s)\n",
      "   Table 1: (1, 6) - columns: ['SET OF RANKINGS', 'FORECAST RANGE', 'STATS FROM', 'POSITION', 'FROM']...\n",
      "   Table 2: (716, 7) - columns: ['RANK', 'PLAYER', 'PLAYER.1', 'AGE', 'TEAM']...\n",
      "   ✓ Found main rankings table with 716 rows\n",
      "\n",
      "======================================================================\n",
      "✓ Successfully scraped using method: pandas_read_html\n",
      "  Shape: (716, 7)\n",
      "  Columns: ['RANK', 'PLAYER', 'PLAYER.1', 'AGE', 'TEAM', 'POS', 'COMMENTS']\n",
      "\n",
      "  First 5 rows:\n",
      "  RANK                   PLAYER  \\\n",
      "0   #1        Victor Wembanyama   \n",
      "1   #2  Shai Gilgeous-Alexander   \n",
      "2   #3              Luka Doncic   \n",
      "3   #4             Nikola Jokic   \n",
      "4   #5          Cade Cunningham   \n",
      "\n",
      "                                            PLAYER.1   AGE TEAM    POS  \\\n",
      "0  #1 Victor Wembanyama (SA, C) AGE: 21.9  12 GP ...  21.9   SA      C   \n",
      "1  #2 Shai Gilgeous-Alexander (OKC, PG) AGE: 27.4...  27.4  OKC     PG   \n",
      "2  #3 Luka Doncic (LAL, PG,SG) AGE: 26.7  13 GP 0...  26.7  LAL  PG,SG   \n",
      "3  #4 Nikola Jokic (DEN, C) AGE: 30.8  17 GP 0.62...  30.8  DEN      C   \n",
      "4  #5 Cade Cunningham (DET, PG,SG) AGE: 24.2  15 ...  24.2  DET  PG,SG   \n",
      "\n",
      "                                            COMMENTS  \n",
      "0  12 GP 0.502 FG% 0.857 FT% 1.7 3PM 26.2 PTS 12....  \n",
      "1  19 GP 0.548 FG% 0.897 FT% 2.2 3PM 32.6 PTS 4.9...  \n",
      "2  13 GP 0.470 FG% 0.789 FT% 3.7 3PM 35.2 PTS 8.8...  \n",
      "3  17 GP 0.626 FG% 0.853 FT% 2.1 3PM 29.6 PTS 12....  \n",
      "4  15 GP 0.445 FG% 0.828 FT% 1.9 3PM 28.1 PTS 6.1...  \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test scraping Hashtag Basketball Dynasty Rankings with multiple approaches\n",
    "test_url = \"https://hashtagbasketball.com/fantasy-basketball-dynasty-rankings\"\n",
    "print(\"=\" * 70)\n",
    "print(\"Testing Hashtag Basketball Dynasty Rankings Scraping\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def scrape_hashtag_dynasty_rankings(url):\n",
    "    \"\"\"\n",
    "    Specialized scraper for Hashtag Basketball Dynasty Rankings page.\n",
    "    Tries multiple methods to extract the rankings table.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Method 1: Try pandas read_html on all tables\n",
    "        print(\"\\n1. Trying pandas read_html on all tables...\")\n",
    "        from io import StringIO\n",
    "        try:\n",
    "            tables = pd.read_html(StringIO(response.text))\n",
    "            print(f\"   Found {len(tables)} table(s)\")\n",
    "            for i, df in enumerate(tables):\n",
    "                print(f\"   Table {i+1}: {df.shape} - columns: {list(df.columns)[:5]}...\")\n",
    "                if len(df) > 50:  # Likely the main rankings table\n",
    "                    print(f\"   ✓ Found main rankings table with {len(df)} rows\")\n",
    "                    return df, \"pandas_read_html\"\n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Failed: {e}\")\n",
    "        \n",
    "        # Method 2: Use scrapy selector to find tables with specific structure\n",
    "        print(\"\\n2. Trying scrapy selector to find rankings table...\")\n",
    "        selector = Selector(text=response.text)\n",
    "        \n",
    "        # Look for table elements\n",
    "        tables = selector.css('table')\n",
    "        print(f\"   Found {len(tables)} table elements\")\n",
    "        \n",
    "        # Try to find table with rankings data\n",
    "        for i, table in enumerate(tables):\n",
    "            table_html = table.get()\n",
    "            try:\n",
    "                df = pd.read_html(StringIO(table_html))[0]\n",
    "                if len(df) > 50:\n",
    "                    print(f\"   ✓ Found rankings table {i+1} with {len(df)} rows\")\n",
    "                    return df, f\"scrapy_table_{i+1}\"\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Method 3: Look for data in script tags or data attributes (JS-loaded content)\n",
    "        print(\"\\n3. Checking for JavaScript-loaded data...\")\n",
    "        scripts = selector.css('script::text').getall()\n",
    "        data_scripts = [s for s in scripts if 'rankings' in s.lower() or 'player' in s.lower()]\n",
    "        if data_scripts:\n",
    "            print(f\"   Found {len(data_scripts)} potentially relevant script tags\")\n",
    "            # Could parse JSON from scripts if needed\n",
    "        \n",
    "        # Method 4: Check page structure and key elements\n",
    "        print(\"\\n4. Analyzing page structure...\")\n",
    "        title = selector.css('h1::text, title::text').get()\n",
    "        print(f\"   Page title: {title}\")\n",
    "        \n",
    "        # Look for specific elements that might contain rankings\n",
    "        player_rows = selector.css('tr, .player-row, [data-rank]')\n",
    "        print(f\"   Found {len(player_rows)} potential player row elements\")\n",
    "        \n",
    "        # Method 5: Try to extract data from visible text patterns\n",
    "        print(\"\\n5. Attempting text-based extraction...\")\n",
    "        page_text = selector.css('body::text').getall()\n",
    "        text_content = ' '.join(page_text[:100])  # First 100 text elements\n",
    "        if 'Wembanyama' in text_content or 'Jokic' in text_content:\n",
    "            print(\"   ✓ Found player names in page text (page may need JS rendering)\")\n",
    "        \n",
    "        return None, \"all_methods_failed\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, \"error\"\n",
    "\n",
    "# Run the scraper\n",
    "df, method = scrape_hashtag_dynasty_rankings(test_url)\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"✓ Successfully scraped using method: {method}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"\\n  First 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "else:\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"✗ Failed to extract rankings table\")\n",
    "    print(\"  Note: This page may require JavaScript rendering (Selenium needed)\")\n",
    "    print(f\"{'=' * 70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fd8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stored Hashtag Dynasty Rankings DataFrame\n",
      "  Shape: (716, 7)\n",
      "  Columns: ['RANK', 'PLAYER', 'PLAYER.1', 'AGE', 'TEAM', 'POS', 'COMMENTS']\n",
      "\n",
      "  Sample data (first 10 rows):\n",
      "  RANK                   PLAYER  \\\n",
      "0   #1        Victor Wembanyama   \n",
      "1   #2  Shai Gilgeous-Alexander   \n",
      "2   #3              Luka Doncic   \n",
      "3   #4             Nikola Jokic   \n",
      "4   #5          Cade Cunningham   \n",
      "5   #6          Anthony Edwards   \n",
      "6   #7              Evan Mobley   \n",
      "7   #8             Cooper Flagg   \n",
      "8   #9            Chet Holmgren   \n",
      "9  #10    Giannis Antetokounmpo   \n",
      "\n",
      "                                            PLAYER.1   AGE TEAM       POS  \\\n",
      "0  #1 Victor Wembanyama (SA, C) AGE: 21.9  12 GP ...  21.9   SA         C   \n",
      "1  #2 Shai Gilgeous-Alexander (OKC, PG) AGE: 27.4...  27.4  OKC        PG   \n",
      "2  #3 Luka Doncic (LAL, PG,SG) AGE: 26.7  13 GP 0...  26.7  LAL     PG,SG   \n",
      "3  #4 Nikola Jokic (DEN, C) AGE: 30.8  17 GP 0.62...  30.8  DEN         C   \n",
      "4  #5 Cade Cunningham (DET, PG,SG) AGE: 24.2  15 ...  24.2  DET     PG,SG   \n",
      "5  #6 Anthony Edwards (MIN, PG,SG) AGE: 24.3  14 ...  24.3  MIN     PG,SG   \n",
      "6  #7 Evan Mobley (CLE, PF,C) AGE: 24.4  18 GP 0....  24.4  CLE      PF,C   \n",
      "7  #8 Cooper Flagg (DAL, PG,SG,SF) AGE: 18.9  18 ...  18.9  DAL  PG,SG,SF   \n",
      "8  #9 Chet Holmgren (OKC, PF,C) AGE: 23.6  15 GP ...  23.6  OKC      PF,C   \n",
      "9  #10 Giannis Antetokounmpo (MIL, PF,C) AGE: 31....  31.0  MIL      PF,C   \n",
      "\n",
      "                                            COMMENTS  \n",
      "0  12 GP 0.502 FG% 0.857 FT% 1.7 3PM 26.2 PTS 12....  \n",
      "1  19 GP 0.548 FG% 0.897 FT% 2.2 3PM 32.6 PTS 4.9...  \n",
      "2  13 GP 0.470 FG% 0.789 FT% 3.7 3PM 35.2 PTS 8.8...  \n",
      "3  17 GP 0.626 FG% 0.853 FT% 2.1 3PM 29.6 PTS 12....  \n",
      "4  15 GP 0.445 FG% 0.828 FT% 1.9 3PM 28.1 PTS 6.1...  \n",
      "5  14 GP 0.475 FG% 0.814 FT% 3.4 3PM 28.0 PTS 4.8...  \n",
      "6  18 GP 0.496 FG% 0.593 FT% 1.5 3PM 18.7 PTS 8.7...  \n",
      "7  18 GP 0.451 FG% 0.793 FT% 1.0 3PM 15.9 PTS 6.4...  \n",
      "8  15 GP 0.547 FG% 0.842 FT% 1.5 3PM 17.9 PTS 7.9...  \n",
      "9  13 GP 0.629 FG% 0.636 FT% 0.7 3PM 31.2 PTS 10....  \n"
     ]
    }
   ],
   "source": [
    "# Store the scraped hashtag rankings dataframe\n",
    "if df is not None:\n",
    "    hashtag_dynasty_rankings_df = df.copy()\n",
    "    print(f\"✓ Stored Hashtag Dynasty Rankings DataFrame\")\n",
    "    print(f\"  Shape: {hashtag_dynasty_rankings_df.shape}\")\n",
    "    print(f\"  Columns: {list(hashtag_dynasty_rankings_df.columns)}\")\n",
    "    \n",
    "    # Show a sample of the data\n",
    "    print(f\"\\n  Sample data (first 10 rows):\")\n",
    "    print(hashtag_dynasty_rankings_df.head(10))\n",
    "else:\n",
    "    print(\"✗ No data to store. Check the scraping output above for details.\")\n",
    "    hashtag_dynasty_rankings_df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbde8c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"12 GP 0.502 FG% 0.857 FT% 1.7 3PM 26.2 PTS 12.9 REB 4.0 AST 1.0 STL 3.6 BLK 3.6 TO  Fun fact: if you only used Wemby's defensive categories (REB, STL, BLK), he still ranks among the top five players in 9-cat rankings.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_dynasty_rankings_df[\"COMMENTS\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scraped articles to LangChain Documents for vector storage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def articles_to_documents(articles, document_type='web_article'):\n",
    "    \"\"\"\n",
    "    Convert scraped articles to LangChain Documents.\n",
    "    \n",
    "    Args:\n",
    "        articles: List of article dictionaries with 'url', 'title', 'content', 'source'\n",
    "        document_type: Type identifier for the documents (default: 'web_article')\n",
    "    \n",
    "    Returns:\n",
    "        List of LangChain Document objects\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for article in articles:\n",
    "        if article and article.get('content'):\n",
    "            doc = Document(\n",
    "                page_content=article['content'],\n",
    "                metadata={\n",
    "                    'source': article.get('url', ''),\n",
    "                    'title': article.get('title', ''),\n",
    "                    'source_domain': article.get('source', ''),\n",
    "                    'type': document_type\n",
    "                }\n",
    "            )\n",
    "            docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "# Convert scraped articles to documents\n",
    "article_docs = articles_to_documents(scraped_articles, document_type='web_article')\n",
    "\n",
    "print(f\"Created {len(article_docs)} LangChain documents\")\n",
    "if article_docs:\n",
    "    print(f\"Sample document: {article_docs[0].metadata}\")\n",
    "    print(f\"Content preview: {article_docs[0].page_content[:200]}...\")\n",
    "else:\n",
    "    print(\"No documents created. Make sure you've scraped some articles first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClutchAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "defcc9333e9a5f2ae70a9938c73917410db5241f2c086366aeff6301cac22d61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
